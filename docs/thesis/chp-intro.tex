\chapter{Introduction}\label{chp:introduction}

% Too flairy?
%To most humans, driving a car may seem like a trivial task. The main idea behind it, disregarding
%the problem of finding a route to your destination, is simple: to stay in between lane markings and
%not run over anything (or anyone). However, this simplicity doesn't translate well to machines. The
%complexity and variability of input for lane markings depend not only on the location and
%background of the pathway, but also the general conditions of the road itself. Coupled with the
%necessity of real-time decision making on a high-speed heavy-weight vehicle, a wrong
%prediction could prove fatal. However, there have been many promising results the past few years
%on autonomous driving, mainly thanks to advances in computer vision and machine learning, and
%although state-of-the-art models are extremely complex, they still rely on the same principle of
%following a lane through visual cues.

In this chapter we first describe the motivations and objectives of this thesis. Next, we describe
the structure of this document.

\section{Motivation and objectives}

Self-driving is a challenging computer vision task, mainly due to its inherent complexity and the
necessity for real-time decision making. Although there have been many promising results the past
few years on autonomous driving, the task still relies on the underlying problem of following a
pathway through visual cues (usually road markings). A possible approach to this task is through
imitation learning by means of image classification. That is, the agent tasked with driving should
be able to reliably mimic human behavior by correctly classifying whether to turn, stop or go
straight given an image captured in front of the car.

Mobile robots are low cost machines capable of movement. These robots are usually small, and
because of their size and cost often don't have the same performance capabilities as a desktop
computer. However, these domain traits make mobile robot self-driving a very similar analogue to
real-world autonomous cars. Processing power and memory constraints play a big role in this case,
and translate well to embedded systems present in a self-driving car.

Sum-product networks (SPNs) are probabilistic graphical models that are able to represent a wide
range of tractable probability distributions of many variables. SPNs have shown impressive results
in several domains, and particularly that of image classification. Their deep architecture seems to
capture features and contexts well, and since inference is computed in time linear to the network's
edges, SPNs are promising models for fast inference in self-driving.

In this work, we attempt to model self-driving of mobile robots through image classification. For
the task of classification our objective is to use sum-product networks learned discriminatively,
though we also give results for generative SPNs, comparing not only generative and discriminative
learning, but also different SPN architectures.

\section{Thesis structure}

This thesis is structured as follows. In~\autoref{chp:spn}, we first provide background on
sum-product networks, where we formally define an SPN, present key properties on their structure,
explain how to compute exact inference and find an approximation of the maximum a posteriori
probability (MAP).

In~\autoref{chp:weights}, we show how to compute the partial derivatives with respect to a sub-SPN
and to its weights, leading on how to perform gradient descent and then on learning the weights of
the network through gradient descent both generatively and discriminatively.

\Cref{chp:structure} is dedicated to algorithms for learning the structure of an SPN\@. We explain
the two structural learning algorithms that were used in the experiments.

For~\autoref{chp:modelling}, we first show how we model self-driving as an image classification
problem. We then give a brief explanation on the dataset used for training and testing. We then
formalize how we extract inference for self-driving.

\Cref{chp:hardware} is dedicated to explaining the hardware aspects of this work. We describe the
processing unit used for inference and the unit used for handling the motors. We also explain how
communication between the two is done.

In~\autoref{chp:benchmarks}, we first explain how image pre-processing was done. Accuracy results
and timings on training and inference on different SPN architectures and weight learning methods
are then presented.

We finally implement and show results of the self-driving robot on a real world application
in~\autoref{chp:realworld}.

Finally, in~\autoref{chp:conclusion} we give our conclusions and provide some discussion of the
results.

