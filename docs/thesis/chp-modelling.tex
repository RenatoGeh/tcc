%&tex

\chapter{Modelling the problem}\label{chp:modelling}

In this chapter we formally define a possible model for the mobile robots self-driving problem.  We
first present this problem as an imitation learning through image classification problem. We then
describe the dataset intended as training set for image classification. Finally, we discuss the
problems of inference speed we should encounter when dealing with a mobile robot, and provide a
concurrent programming solution for our particular problem.

\section{The problem}

One of the main problems of self-driving is to follow a certain pathway. In real life, a
self-driving car should be able to maintain itself centered on a lane, more specifically inbetween
lane markings. We address this particular subproblem of self-driving. This is achieved by
considering this situation as an imitation learning application.

Imitation learning consists of an agent accurately mimicking human behavior. In our case, we wish
for such an agent to simulate the behavior of keeping a car centered on a single lane. We model
this particular situation by use of image classification. The agent, in this case the self-driving
car, should reliably identify when to turn and when to go straight my solely ``looking'' at the
road. This can be achieved through the use of image classification, as a turn tends to have
different visual features then a straight lane.

Whilst this comes naturally to humans, machines have trouble identifying these features by
themselves.  Noise and object occlusion play a big role in how reliably the agent behaves. A
possible obstruction of the agent's view could turn fatal in a real-life scenario. However, with
the advent of more complex models in machine learning, modelling this problem through image
classification has become a feasible solution.

Our approach to self-driving in mobile robots consists of a very simplified and purely reactive
image classification problem. The mobile robot should follow a lane and turn accordingly based on
its image input of its front view.

We define a classification variable, which we will denote by $Y$, as an indicator of what the robot
should do. The function $\Val(Y)$ defines the set of all possible values of $Y$. In our case,
$\Val(Y)=\{\Left,\Right, \Up\}$, each meaning that the robot should ``go left'', ``go right'' and
``go straight'' respectively.

Let $X=\{X_1,X_2,\ldots,X_n\}$ be the set of variables that compose an image, where each $X_i$
represents a pixel of a flattened image. Our entire scope is defined by the set $W=X\cup Y$. Our
objective is to reliably guess $Y$'s value based solely on the values of $X$. That is, we wish to
find

\begin{equation}\label{eq:model-prob}
  \argmax_{y\in\Val(Y)} P(Y=y|X) = \argmax_{y\in\Val(Y)} \frac{P(Y=y,X)}{P(X)}\propto
  \argmax_{y\in\Val(Y)} P(Y=y,X).
\end{equation}

Where we assume the existence of an underlying probability distribution that correctly models the
classification problem. Ultimately, our goal is to find this distribution by ``learning'' from data
through the learning algorithms described in~\autoref{chp:weights} and~\autoref{chp:structure}.

Once learned, the SPN is able to find the MAP probabilities and states that correctly predict the
most probable values of $Y$ given an image. Note how the LHS of~\autoref{eq:model-prob} can be
computed with a single pass with the approximate max-product algorithm. Alternatively, we can also
compute the exact max values by computing each possible $y\in\Val(Y)$ with a single forward pass
through the SPN.

\section{The dataset}

For training, we used Moraes and Salvatore's self-driving dataset (\cite{self-driving}). Every
image has dimensions $45\times 80$, with three additional channels for RGB. The dataset is split
into three sets, corresponding to training, test and validation data. Each image contains a label
indicating whether the robot should go straight, turn left or turn right. These actions are labeled
as $0$, $1$ and $2$.

\begin{figure}[h]
  \centering\includegraphics[width=0.31\textwidth]{imgs/sample_left.png}
  \includegraphics[width=0.31\textwidth]{imgs/sample_up.png}
  \includegraphics[width=0.31\textwidth]{imgs/sample_right.png}
  \caption{Sample images from training dataset.\label{fig:dataset_sample}}
\end{figure}

\autoref{fig:dataset_sample} showcases sample images from the training dataset. The leftmost image
has label $\Left$, the one on the middle is $\Up$ and the one on the right $\Right$. It is possible
to observe that images do not have uniform lightning and lane markings are irregular. This adds a
noise effect to the images.

The original dataset is already reduced in size. However, the presence of color is not so important
to identify the correct values of $Y$. If we compare~\autoref{fig:dataset_sample}
and~\autoref{fig:dataset_gray}, lane markings are still very much visible.

\begin{figure}[h]
  \centering\includegraphics[width=0.31\textwidth]{imgs/gray_left.png}
  \includegraphics[width=0.31\textwidth]{imgs/gray_up.png}
  \includegraphics[width=0.31\textwidth]{imgs/gray_right.png}
  \caption{Grayscale sample images from training dataset.\label{fig:dataset_gray}}
\end{figure}

We can try to further reduce the complexity of the dataset at the same time preserving its most
informational features by attempting to reduce the number of possible values of each pixel through
image quantization. This transformation turned out to be very meaningful in terms of both training
speed and accuracy, as we detail in a later chapter. However, noise is still very much present in
the images, as~\autoref{fig:dataset_transformed} shows.

\begin{figure}[h]
  \centering\includegraphics[width=0.31\textwidth]{imgs/trans_left.png}
  \includegraphics[width=0.31\textwidth]{imgs/trans_up.png}
  \includegraphics[width=0.31\textwidth]{imgs/trans_right.png}
  \caption{Quantized sample images from training dataset.\label{fig:dataset_transformed}}
\end{figure}

Another possible transformation we can apply on the dataset is binarization. However, traditional
``hard'' binarization with a fixed $k$ threshold on the image could potentially cause completely
black or white images due to a poor choice of $k$. This can countered with two possible solutions.
Either through adaptive threshold where we choose $k$ either by a mean measurement or through a
gaussian, or by use of Otsu's binarization (\cite{otsu}). We found that Otsu's method, coupled with
a prior gaussian blur transformation on each image, proved the most capable of correctly applying
binarization in our dataset.

\begin{figure}[h]
  \centering\includegraphics[width=0.31\textwidth]{imgs/binary_left.png}
  \includegraphics[width=0.31\textwidth]{imgs/binary_up.png}
  \includegraphics[width=0.31\textwidth]{imgs/binary_right.png}
  \caption{Binarized sample images from training dataset.\label{fig:dataset_binary}}
\end{figure}

\autoref{fig:dataset_binary} shows the final result of applying a combination of gaussian blur and
Otsu's binarization.

\section{The model}

%As we have seen in~\autoref{chp:spn}, we can compute this probability in two different ways. Either
%by computing each $Y$ value by means of a forward pass on the SPN $S(Y=y,X)$, or through the
%approximate MAP $M(Y=y,X)$. We address the computational and approximation problems of both later
%in this chapter.
%In this chapter we ignore the system control aspect of the robot. We address this issue
%in~\autoref{chp:hardware}.
